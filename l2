#!/usr/bin/perl

use DBI;
use JSON;


# Fields (columns) present in the MASTER or MASTER.txt files
# [ field name, sql data type ]
$master_fields = [ [ 'n_number', 'varchar(5)' ],
	           [ 'serial_number', 'varchar(30)'],
                   [ 'mfr_mdl_code', 'varchar(7)'],
                   [ 'eng_mfr_mdl', 'varchar(5)'],
                   [ 'year_mfr', 'varchar(4)'],
                   [ 'type_registrant', 'varchar(1)'],
                   [ 'name', 'varchar(50)'],
                   [ 'street', 'varchar(33)'],
                   [ 'street2', 'varchar(33)'],
                   [ 'city', 'varchar(18)'],
                   [ 'state', 'varchar(2)'],
                   [ 'zip_code', 'varchar(10)'],
                   [ 'region', 'varchar(1)'],
                   [ 'county', 'varchar(3)'],
                   [ 'country', 'varchar(2)'],
                   [ 'last_action_date', 'date'],    # YYYYMMDD
                   [ 'cert_issue_date', 'date'],     # YYYYMMDD 
                   [ 'certification', 'varchar(10)'],  # this is the big chunk of data that contains other fields
                   [ 'type_aircraft', 'varchar(1)'], 
                   [ 'type_engine', 'varchar(2)'], 
                   [ 'status_code', 'varchar(2)'],
                   [ 'mode_s_code', 'varchar(8)'],
                   [ 'fract_owner', 'varchar(1)'],
                   [ 'air_worth_date', 'date'],      # YYYYMMDD
                   [ 'other_names_1', 'varchar(50)'],
                   [ 'other_names_2', 'varchar(50)'],
                   [ 'other_names_3', 'varchar(50)'],
                   [ 'other_names_4', 'varchar(50)'],
                   [ 'other_names_5', 'varchar(50)'],
                   [ 'expiration_date', 'date'],      # YYYYMMDD  This field missing from the earliest files
                   [ 'unique_id', 'varchar(8)'],
                   [ 'kit_mfr', 'varchar(30)'],
                   [ 'kit_model', 'varchar(20)'],
                   [ 'mode_s_code_hex', 'varchar(10)']
                 ];
my @date_fields_in_master = map {$_->[0]} grep {$_->[1] eq 'date'} @{$master_fields};

my $mysql = DBI->connect('DBI:mysql:airwho;host=localhost', 'django', 'fjfjfj');

# TODO consider a threaded implementation here
my $files = import_files->new();

# Load all of the files in the import_files directory structure starting with $max_date.
# At this point we don't have record that the previous run was completed successfully, so we have to consider that the
# changes stored for $max_date might not be complete.  We want inserting a/d/c records into master_changes to be idempotent
# so it's safe to redo some or all of the changes for $max_date.  For efficiency, consider adding a table to record which 
# files have been successfully imported.
($max_date) = @{$mysql->selectcol_arrayref('select max(date_from) from master_changes')};

  my $first;  # index in @all of the first file we're going to load.  We will compare this file with the next-newest one.

  # find out the most recent file represented in master_changes.  Starting with that file (because we can't be sure that the load of that file was successful)
  # re-load the file (load should be idempotent) and then compare the previous file and load that until we get to the first file.
  # Compare each of the fields with the previous file.  Either the fields must be the same or missing completely in the older file.  Otherwise, insert the row into master_history.
  ($min_date) = @{$mysql->selectcol_arrayref('select min(date_from) from master_changes')};
  print "min_date is $min_date\n\n";
  if ($min_date) {
    # find the index in @all of the file with date min_date
    for (my $i=0; $i<$#all and (${date_from_filename($all[$i])}[0] le $min_date); $i++) {$first=$i;}}
  else {
    $first = $#all-1;
    print "The most recent file is $all[$first]\n\n";
    }

  # Go through each file from $first to the last one
  my $new = get_file($all[$first+1]);
  my ($new_date) = date_from_filename($all[$first+1]);
  for (my $i=$first; $i>=0; $i--) {
    print "Comparing $i with $i+1: $all[$i] with $all[$i+1]\n";
    my $old = get_file($all[$i]);
    my ($old_date) = date_from_filename($all[$i]);
    compare_two_datasets($old, $old_date, $new, $new_date);
    my $new=$old;
    $new_date=$old_date;
    }
  }



sub compare_two_datasets {
  my @old = @{+shift};
  my $old_date = shift;
  my @new = @{+shift};
  my $new_date = shift;

  # Convert $new and $old into hashes
  # The serial number is in position 1 and mfg/model code is in position 2.  Use that as the hash key.
  # The "unique_id" field might be better but that field is not present in the earlier files; it was added later.
  %new = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$new[0]}] ] } @new;
  %old = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$old[0]}] ] } @old;

  # Using a prepared statement is much faster than not (but still the biggest bottlneck)
  my @fields = map {$_->[0]} @{$master_fields};
  my $insert_into_master_stmt = $mysql->prepare('insert into master_changes ( date_from, date_to, change_type,'.join(', ', @fields).') values (?,?,?'. (',?'x(scalar @fields) ).')');

  my $field_count = scalar @{$master_fields};

  # Iterate through $new, looking for anything not in $old - that will give us added records.
  # Get the changed records also on this pass because we already have the new record (which is what we want to store)
  foreach $n(@new) {
    my $key = $n->[2].'|'.$n->[1];
    if ( ! $old{$key}) {
      if ($v) {print "Added: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'A', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($n->[$_]) : $n->[$_] } 0..($field_count-1) ) );
      }
    elsif ( ! (@{$new{$key}} ~~ @{$old{$key}})) {
      if ($v) {print "Changed: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'C', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($n->[$_]) : $n->[$_] } 0..($field_count-1) ) );
      }
    }
  # Iterate through $old, looking for anything not in $new - that will give us deleted records
  # the compare function is tricky, because at several times through the history of these files, fields have been added.
  # fortunately, all of the added fields have been added to the end of the previous set of fields.
  # NB originally we did NOT want to consider as changed a file that just has fields added.  Now we do.
  foreach $o(@old) {
    my $key = $o->[2].'|'.$o->[1];
    unless ($new{$key}) {
      if ($v) {print "Deleted: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'D', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($o->[$_]) : $o->[$_] } 0..($field_count-1) ) );
      }
    }
  }


sub trim { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s };

# The FAA uses date format YYYYMMDD.  MySQL uses yyyy-mm-dd.  This accept a date in the FAA's format and returns it in MySQL's format
sub format_date {
  my $date = shift;
  if (my ($y, $m, $d) = $date =~ /(\d{4})(\d{2})(\d{2})/g) {return "$y-$m-$d";}
  return undef;
  }

sub get_file {
  my $filename=shift;
  copy_and_unzip_file_into_temp($filename);
  ($d)=date_from_filename($filename);
  open my $f, '<', "$home/temp/MASTER.txt";
  read $f, my $buffer, -s $filename;
  my @rows = split("\r\n", $buffer);
  @rows = map { [ map {trim($_)} split /\s*,\s*/, $_ ] } @rows;
  return \@rows;
  }



sub all_files {
  my @all;  # The array we're going to push the list of unique files onto.
  my $prev_day_size = undef; 
  my @years = grep {/\d{4}/} <"$home/*">;

  foreach my $year(@years) {
    my @days = <"$year/*">;
    foreach my $day(@days) {
      # Many files are repeats of previous day, because the FAA hadn't updated the file when we downloaded it.  This uses the files size to exclude those duplicates
      my $s = -s $day;
      if ($s != $prev_day_size) {
        $prev_day_size = $s;
	push @all, $day;
        }
      }
    }
  return @all;
  }



sub get_field_names_from_current_file {
  # get the field names from the first row
  open my $f, '<', "$home/temp/MASTER.txt";;
  my $fields = <$f>;
  chomp $fields;
  $fields =~ s/\W+$//;  # Removes comma and any other odd characters at the end of the line
  $fields =~ s/^\W+//;  # Removes comma and any other odd characters at the front of the line

  print $fields;
  # Split the header into an array of field names, changing all of the dashes, spaces, and parentheses to underscores
  # and then removing leading and trailing underscores from each field name
  @fields = map { local $_=$_; s/^_|_$//g; lc $_} map { local $_=$_; s/[- ()]/_/g; $_ } split ',', $fields;
  print join(', ', @fields)."\n";

  create_table(\@fields);
  }


# Given a year, month, and day, return the filename for that date.  If it doesn't exist, return false.
sub lookup_filename {
  my ($y, $m, $d) = @_;
  my ($filename) = grep {/$y-$m-$d/} <"$home/$y/*">;
  #die "* * * * * the filename is $filename * * * * *\n";
  return $filename;
  }



sub create_table {
  my $query = "create table if not exists MASTER (".(join(', ', map { "$_->[0] $_->[1]" } @{$master_fields} ) ).")";
  print "\n\n$query\n\n";
  $mysql->do($query);
  $mysql->do("truncate MASTER"); # because of the "if not exists" clause we might not have created a new table.  In either case, ensure the table is empty.
  load_data( );
  }


sub load_data {
  my @fields = @{+shift};
  my $field_definitions = shift;
  $query = "load data local infile '$home/temp/MASTER.txt' into table MASTER fields terminated by ',' enclosed by '\"' lines terminated by '\\r\\n' ignore 1 lines (".
           join(',', map {"\@$_"} @fields).") set ".
	   join(', ', map {"$_ = ".($field_definitions->{$_} eq 'date' ? "str_to_date(\@$_, '%Y%m%d%')" : "RTRIM(\@$_)") } @fields);
  print "$query\n\n";
  $mysql->do($query);
  if ($mysql->errstr) {print "Error: ".$mysql->errstr."\n";}
  print "Data loaded.\n";
  }



# This class represents the set of imported files that exists on disk, as well as an iterator over that set and
# some utility functions to create and manage the data sets extracted from those files.
# Although not currently implemented, this might be altered slightly to permit parallel loading of files through
# multiple instances - though that would require provisioning for multiple temp directories with different names. 
package import_files;

my @all;
my $home = '/var/aircraft';
my $current_file_path;  
my $current_file_id;  # subscript of this element in the @all array

sub new {
  my $class=shift;
  my $self={};
  bless $self, $class;
  return $self;
  }


sub all_files {
  my $self=shift;
  my $prev_day_size = undef;
  my @years = grep {/\d{4}/} <"$home/*">;

  foreach my $year(@years) {
    my @days = <"$year/*">;
    foreach my $day(@days) {
      # Many files are repeats of previous day, because the FAA hadn't updated the file when we downloaded it.
      # This uses the file's size to exclude those duplicates.
      # Also, 30mb seems like a reasonable estimate to exclude the bulk of the remaining problem files
      my $s = -s $day;
      if ($s != $prev_day_size and $s>30000000 {
        $prev_day_size = $s;
        push @all, $day;
        }
      }
    }
  return @all;
  }


sub copy_and_unzip_file_into_temp {
  my $self = shift;
  my $filename = shift;
  my ($date, $y, $m, $d) = date_from_filename($filename);

  print "copy_and_unzip_file_into_temp: Loading $filename into temp\n";
  # If the source file isn't already copied to the temp directory, do so.
  unless (-e "$home/temp/$date.zip") {
    if ($filename) {
      if (-e "$home/temp") {`rm -r $home/temp/*`;}
      else {mkdir "$home/temp";}
      `cp $filename $home/temp/$date.zip`;
      }
    else {die "Couldn't find a file for $date\n";}
    }

  print "unzip $home/temp/$y-$m-$d.zip -d $home/temp\n";
  `unzip $home/temp/$y-$m-$d.zip -d $home/temp`;
  # If the source file is not already unzipped, unzip it.
  my $master_filename;
  if (-e "$home/temp/MASTER.txt") {rename "$home/temp/MASTER", "$home/temp/MASTER.txt";}
  }


# static method - call on the package, not the instance.
sub date_from_filename {
  my $filename=shift;
  my ($y, $m, $d) = $filename =~ /(\d{4})-(\d{2})-(\d{2})/;
  return ("$y-$m-$d", $y, $m, $d);
  }

