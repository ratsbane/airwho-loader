#!/usr/bin/perl

use DBI;
use JSON;

my $mysql = DBI->connect('DBI:mysql:airwho;host=localhost', 'django', 'fjfjfj');


my $home = '/var/aircraft';
my @all = all_files();

if ($ARGV[0] eq 'backwards') {
  # Go through all of the files in reverse chron order and load the master_changes table
  load_backwards();
  }
elsif (my ($y, $m, $d) = $ARGV[0]=~/(\d\d\d\d)-(\d\d)-(\d\d)/) {
  print "Loading files for $y-$m-$d\n";
  $filename=lookup_filename($y, $m, $d);
  copy_and_unzip_file_into_temp($filename);
  get_field_names_from_current_file();
  }
else {
  print "Loading all files\n";
  print join("\n", @{$all})."\n";
  }


die;


sub load_backwards {

  my $first;  # index in @all of the first file we're going to load.  We will compare this file with the next-newest one.

  # find out the most recent file represented in master_changes.  Starting with that file (because we can't be sure that the load of that file was successful)
  # re-load the file (load should be idempotent) and then compare the previous file and load that until we get to the first file.
  # Compare each of the fields with the previous file.  Either the fields must be the same or missing completely in the older file.  Otherwise, insert the row into master_history.
  ($min_date) = @{$mysql->selectcol_arrayref('select min(date_from) from master_changes')};
  print "min_date is $min_date\n\n";
  if ($min_date) {
    # find the index in @all of the file with date min_date
    for (my $i=0; $i<$#all and (${date_from_filename($all[$i])}[0] le $min_date); $i++) {$first=$i;}}
  else {
    # start with the most recent file
    $first = $#all-1;
    print "The most recent file is $all[$first]\n\n";
    }

  # Go through each file from $first to the last one
  my $new = get_file($all[$first+1]);
  my ($new_date) = date_from_filename($all[$first+1]);
  for (my $i=$first; $i>=0; $i--) {
    print "Comparing $i with $i+1: $all[$i] with $all[$i+1]\n";
    my $old = get_file($all[$i]);
    my ($old_date) = date_from_filename($all[$i]);
    compare_two_datasets($old, $old_date, $new, $new_date);
    my $new=$old;
    $new_date=$old_date;
    }
  }

sub trim { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s };

sub compare_two_datasets {
  my @old = @{+shift};
  my $old_date = shift;
  my @new = @{+shift};
  my $new_date = shift;

  # Convert $new and $old into hashes
  # The serial number is in position 1 and mfg/model code is in position 2.  Use that as the hash key.
  # The "unique_id" field might be better but that field is not present in the earlier files; it was added later.
  %new = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$new[0]}] ] } @new;
  %old = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$old[0]}] ] } @old;

  # Iterate through $old, looking for anything not in $new - that will give us deleted records
  foreach $n(@new) {
    my $key = $n->[2].'|'.$n->[1];
    unless ($old{$key}) {
      print "Added in new: ".($key)."\n";
      #insert_into_master_changes( $old_date, $new_date, 'A', $n );
      }
    }
  # Iterate through $new, looking for anything not in $old - that will give us added records. Get the changed records also on this pass.
  # the compare function is tricky, because at several times through the history of these files, fields have been added.
  # fortunately, all of the added fields have been added to the end of the previous set of fields.  We don't want to consider as changed a file
  # that just has fields added, so we will compare an array slice of old and new where the array slice is the length of the shorter of the two arrays
  $slice_length = ($#{$new[0]} > $#{$old[0]}) ? $#{$old[0]} : $#{$new[0]};
  foreach $o(@old) {
    my $key = $o->[2].'|'.$o->[1];
    unless ($new{$key}) {
      print "Removed in new: $key\n";
      #insert_into_master_changes($o);
      }
    unless (@{$new{$key}}[0..$slice_length] ~~ @{$old{$key}}[0..$slice_length]) {
      print "Changed: $key\n";
      #insert_into_master_changes($o);
      }
    }
  }


sub insert_into_master_changes {
  my $date_from = shift;
  my $date_to = shift;
  my $change_type = shift;  # A = Added; D = Deleted; C = Changed
  my @record = @{+shift};

  $query = 'insert into master_changes ( change_type, date_from, date_to, '.join(', ', @fields).') values (?,?,?,'.join(', ', ('?'x(scalar @fields)) ).')';
  print "$date_from, $date_to, $change_type: $query\n";
  }


sub get_file {
  my $filename=shift;
  copy_and_unzip_file_into_temp($filename);
  ($d)=date_from_filename($filename);
  open my $f, '<', "$home/temp/MASTER.txt";
  read $f, my $buffer, -s $filename;
  my @rows = split("\r\n", $buffer);
  @rows = map { [ map {trim($_)} split /,\W*/, $_ ] } @rows;
  return \@rows;
  }


sub date_from_filename {
  my $filename=shift;
  my ($y, $m, $d) = $filename =~ /(\d{4})-(\d{2})-(\d{2})/;
  return ("$y-$m-$d", $y, $m, $d);
  }

sub all_files {

  my @all;  # The array we're going to push the list of unique files onto.
  my $prev_day_size = undef; 
  my @years = grep {/\d{4}/} <"$home/*">;

  foreach my $year(@years) {
    my @days = <"$year/*">;
    foreach my $day(@days) {
      # Many files are repeats of previous day, because the FAA hadn't updated the file when we downloaded it.  This uses the files size to exclude those duplicates
      my $s = -s $day;
      if ($s != $prev_day_size) {
        $prev_day_size = $s;
	push @all, $day;
        }
      }
    }
  return @all;
  }


sub copy_and_unzip_file_into_temp {
  my $filename = shift;
  my ($date, $y, $m, $d) = date_from_filename($filename);

  print "copy_and_unzip_file_into_temp: Loading $filename into temp\n";
  # If the source file isn't already copied to the temp directory, do so.
  unless (-e "$home/temp/$date.zip") {
    if ($filename) {
      if (-e "$home/temp") {`rm -r $home/temp/*`;}
      else {mkdir "$home/temp";}
      `cp $filename $home/temp/$date.zip`;
      }
    else {die "Couldn't find a file for $date\n";}
    }

  print "unzip $home/temp/$y-$m-$d.zip -d $home/temp\n";
  `unzip $home/temp/$y-$m-$d.zip -d $home/temp`;
  # If the source file is not already unzipped, unzip it.
  my $master_filename;
  if (-e "$home/temp/MASTER.txt") {rename "$home/temp/MASTER", "$home/temp/MASTER.txt";}
  }


sub get_field_names_from_current_file {
 
  # get the field names from the first row
  open my $f, '<', "$home/temp/MASTER.txt";;
  my $fields = <$f>;
  chomp $fields;
  $fields =~ s/\W+$//;  # Removes comma and any other odd characters at the end of the line
  $fields =~ s/^\W+//;  # Removes comma and any other odd characters at the front of the line

  print $fields;
  # Split the header into an array of field names, changing all of the dashes, spaces, and parentheses to underscores
  # and then removing leading and trailing underscores from each field name
  @fields = map { local $_=$_; s/^_|_$//g; lc $_} map { local $_=$_; s/[- ()]/_/g; $_ } split ',', $fields;
  print join(', ', @fields)."\n";

  create_table(\@fields);
  }


# Given a year, month, and day, return the filename for that date.  If it doesn't exist, return false.
sub lookup_filename {
  my ($y, $m, $d) = @_;
  my ($filename) = grep {/$y-$m-$d/} <"$home/$y/*">;
  #die "* * * * * the filename is $filename * * * * *\n";
  return $filename;
  }


sub fields {
  return { n_number => 'varchar(5)',
	   serial_number => 'varchar(30)',
           mfr_mdl_code => 'varchar(7)',
           eng_mfr_mdl => 'varchar(5)',
           year_mfr => 'varchar(4)',
           type_registrant => 'varchar(1)',
           name => 'varchar(50)',
           street => 'varchar(33)',
           street2 => 'varchar(33)',
           city => 'varchar(18)',
           state => 'varchar(2)',
           zip_code => 'varchar(10)',
           region => 'varchar(1)',
           county => 'varchar(3)',
           country => 'varchar(2)',
           last_action_date => 'date',  # YYYYMMDD
           cert_issue_date => 'date', # YYYYMMDD 
           certification => 'varchar(10)',  # this is the big chunk of data that contains other fields
           type_aircraft => 'varchar(1)', 
           type_engine => 'varchar(2)', 
           status_code => 'varchar(2)',
           mode_s_code => 'varchar(8)',
           fract_owner => 'varchar(1)',
           air_worth_date => 'date',
           other_names_1 => 'varchar(50)',
           other_names_2 => 'varchar(50)',
           other_names_3 => 'varchar(50)',
           other_names_4 => 'varchar(50)',
           other_names_5 => 'varchar(50)',
           expiration_date => 'date',
           unique_id => 'varchar(8)',
           kit_mfr => 'varchar(30)',
           kit_model => 'varchar(20)',
           mode_s_code_hex => 'varchar(10)'
           };
  }


sub create_table {
  my @fields = @{+shift};
  my $field_definitions = fields();
  my $query = "create table if not exists MASTER (".(join(', ', map { "$_ $field_definitions->{$_}" } @fields ) ).")";
  print "\n\n$query\n\n";
  $mysql->do($query);
  $mysql->do("truncate MASTER"); # because of the "if not exists" clause we might not have created a new table.  In either case, ensure the table is empty.
  load_data(\@fields, $field_definitions);
  }


sub load_data {
  my @fields = @{+shift};
  my $field_definitions = shift;
  $query = "load data local infile '$home/temp/MASTER.txt' into table MASTER fields terminated by ',' enclosed by '\"' lines terminated by '\\r\\n' ignore 1 lines (".
           join(',', map {"\@$_"} @fields).") set ".
	   join(', ', map {"$_ = ".($field_definitions->{$_} eq 'date' ? "str_to_date(\@$_, '%Y%m%d%')" : "RTRIM(\@$_)") } @fields);
  print "$query\n\n";
  $mysql->do($query);
  if ($mysql->errstr) {print "Error: ".$mysql->errstr."\n";}
  print "Data loaded.\n";
  }




# $mysql->do("create index address_city on $tablename(res_street_address, res_city_desc);");
 
