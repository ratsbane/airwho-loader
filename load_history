#!/usr/bin/perl

use DBI;
use JSON;


# Fields (columns) present in the MASTER or MASTER.txt files
# [ field name, sql data type ]
$master_fields = [ [ 'n_number', 'varchar(5)' ],
	           [ 'serial_number', 'varchar(30)'],
                   [ 'mfr_mdl_code', 'varchar(7)'],
                   [ 'eng_mfr_mdl', 'varchar(5)'],
                   [ 'year_mfr', 'varchar(4)'],
                   [ 'type_registrant', 'varchar(1)'],
                   [ 'name', 'varchar(50)'],
                   [ 'street', 'varchar(33)'],
                   [ 'street2', 'varchar(33)'],
                   [ 'city', 'varchar(18)'],
                   [ 'state', 'varchar(2)'],
                   [ 'zip_code', 'varchar(10)'],
                   [ 'region', 'varchar(1)'],
                   [ 'county', 'varchar(3)'],
                   [ 'country', 'varchar(2)'],
                   [ 'last_action_date', 'date'],    # YYYYMMDD
                   [ 'cert_issue_date', 'date'],     # YYYYMMDD 
                   [ 'certification', 'varchar(10)'],  # this is the big chunk of data that contains other fields
                   [ 'type_aircraft', 'varchar(1)'], 
                   [ 'type_engine', 'varchar(2)'], 
                   [ 'status_code', 'varchar(2)'],
                   [ 'mode_s_code', 'varchar(8)'],
                   [ 'fract_owner', 'varchar(1)'],
                   [ 'air_worth_date', 'date'],      # YYYYMMDD
                   [ 'other_names_1', 'varchar(50)'],
                   [ 'other_names_2', 'varchar(50)'],
                   [ 'other_names_3', 'varchar(50)'],
                   [ 'other_names_4', 'varchar(50)'],
                   [ 'other_names_5', 'varchar(50)'],
                   [ 'expiration_date', 'date'],      # YYYYMMDD  This field missing from the earliest files
                   [ 'unique_id', 'varchar(8)'],
                   [ 'kit_mfr', 'varchar(30)'],
                   [ 'kit_model', 'varchar(20)'],
                   [ 'mode_s_code_hex', 'varchar(10)']
                 ];
my @date_fields_in_master = map {$_->[0]} grep {$_->[1] eq 'date'} @{$master_fields};

my $mysql = DBI->connect('DBI:mysql:airwho;host=localhost', 'django', 'fjfjfj');

# Load all of the files in the import_files directory structure starting with $max_date.
# At this point we don't have record that the previous run was completed successfully, so we have to consider that the
# changes stored for $max_date might not be complete.  We want inserting a/d/c records into master_changes to be idempotent
# so it's safe to redo some or all of the changes for $max_date.  For efficiency, consider adding a table to record which 
# files have been successfully imported.
($max_date) = @{$mysql->selectcol_arrayref('select max(date_from) from master_changes')};

# instantiate the files list as all available import files on or after $max_date.  If max_date is undef, start with the first file.
my $files = import_files->new($max_date);

my $o = $files->get_first();
while ($n = $files->get_next()) {
  compare_to_datasets($o, $n);
  $o = $n;
  }



sub compare_two_datasets {
  my @old = @{+shift};
  my $old_date = shift;
  my @new = @{+shift};
  my $new_date = shift;

  # Convert $new and $old into hashes
  # The serial number is in position 1 and mfg/model code is in position 2.  Use that as the hash key.
  # The "unique_id" field might be better but that field is not present in the earlier files; it was added later.
  %new = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$new[0]}] ] } @new;
  %old = map { ($_->[2].'|'.$_->[1]) => [ $_->[0], @{$_}[3..$#{$old[0]}] ] } @old;

  # Using a prepared statement is much faster than not (but still the biggest bottlneck)
  my @fields = map {$_->[0]} @{$master_fields};
  my $insert_into_master_stmt = $mysql->prepare('insert into master_changes ( date_from, date_to, change_type,'.join(', ', @fields).') values (?,?,?'. (',?'x(scalar @fields) ).')');

  my $field_count = scalar @{$master_fields};

  # Iterate through $new, looking for anything not in $old - that will give us added records.
  # Get the changed records also on this pass because we already have the new record (which is what we want to store)
  foreach $n(@new) {
    my $key = $n->[2].'|'.$n->[1];
    if ( ! $old{$key}) {
      if ($v) {print "Added: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'A', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($n->[$_]) : $n->[$_] } 0..($field_count-1) ) );
      }
    elsif ( ! (@{$new{$key}} ~~ @{$old{$key}})) {
      if ($v) {print "Changed: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'C', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($n->[$_]) : $n->[$_] } 0..($field_count-1) ) );
      }
    }
  # Iterate through $old, looking for anything not in $new - that will give us deleted records
  # the compare function is tricky, because at several times through the history of these files, fields have been added.
  # fortunately, all of the added fields have been added to the end of the previous set of fields.
  # NB originally we did NOT want to consider as changed a file that just has fields added.  Now we do.
  foreach $o(@old) {
    my $key = $o->[2].'|'.$o->[1];
    unless ($new{$key}) {
      if ($v) {print "Deleted: $key\n";}
      $insert_into_master_stmt->execute( $old_date, $new_date, 'D', ( map {$master_fields->[$_]->[1] eq 'date' ? format_date($o->[$_]) : $o->[$_] } 0..($field_count-1) ) );
      }
    }
  }


sub trim { my $s = shift; $s =~ s/^\s+|\s+$//g; return $s };


# This class represents the set of imported files that exists on disk, as well as an iterator over that set and
# some utility functions to create and manage the data sets extracted from those files.
# Although not currently implemented, this might be altered slightly to permit parallel loading of files through
# multiple instances - though that would require provisioning for multiple temp directories with different names. 
package import_files;

my $home = '/var/aircraft';

sub new {
  my $class=shift;
  my $min_date = shift;  # optional
  my $self={ min_date => $min_date,
             current_file_path => undef,
             current_file_id => undef,
	     all => all_files($min_date)    # reference to the list of files
            };
  bless $self, $class;
  return $self;
  }


# Return all file paths which are candidates for loading into history.  Pass in the first date that we could use or undef for all
sub all_files {
  my $self = shift;
  my $min_date = shift;  # The minimum date that we will consider for inclusion in this list. Undef is ok; will return all.

  my $prev_day_size = undef;
  my @years = grep {/\d{4}/} <"$home/*">;

  foreach my $year(@years) {
    my @days = <"$year/*">;
    foreach my $day(@days) {
      if ( date_from_filename($day) ge $min_date) {  # returns yyyy-mm-dd.  Rather than use date object, lexical order is fine for this purpose
      
        # Many files are repeats of previous day, because the FAA hadn't updated the file when we downloaded it.
        # This uses the file's size to exclude those duplicates.
        # Also, 30mb seems like a reasonable estimate to exclude the bulk of the remaining problem files
        my $s = -s $day;
        if ($s != $prev_day_size and $s>30000000 {
          $prev_day_size = $s;
          push @all, $day;
          }
        }
      }
    }
  $self->{'all'} = [@all];
  }


sub get_file {
  my $self = shift;
  my $filename=shift;
  if (copy_and_unzip_file_into_temp($filename)) {  # If there's a problem with the file and unzip returns error, don't try loading it. Return false.
  ($d)=date_from_filename($filename);
  open my $f, '<', "$home/temp/MASTER.txt";
  read $f, my $buffer, -s $filename;
  my @rows = split("\r\n", $buffer);
  @rows = map { [ map {trim($_)} split /\s*,\s*/, $_ ] } @rows;
  return \@rows;
  }


sub copy_and_unzip_file_into_temp {
  my $self = shift;
  my $filename = shift;
  my ($date, $y, $m, $d) = date_from_filename($filename);

  if ($v) {print "copy_and_unzip_file_into_temp: Loading $filename into temp\n";}

  # If the source file isn't already copied to the temp directory, do so.
  unless (-e "$home/temp/$date.zip") {
    if ($filename) {
      if (-e "$home/temp") {`rm -r $home/temp/*`;}
      else {mkdir "$home/temp";}
      `cp $filename $home/temp/$date.zip`;
      }
    else {die "Couldn't find a file for $date\n";}
    }

  print "unzip $home/temp/$y-$m-$d.zip -d $home/temp\n";
  `unzip $home/temp/$y-$m-$d.zip -d $home/temp`;
  if (-e "$home/temp/MASTER.txt") {rename "$home/temp/MASTER", "$home/temp/MASTER.txt";}
  }


# static method - call on the package, not the instance.
sub date_from_filename {
  my $filename=shift;
  my ($y, $m, $d) = $filename =~ /(\d{4})-(\d{2})-(\d{2})/;
  return ("$y-$m-$d", $y, $m, $d);
  }

